{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier\n",
    "\n",
    "Let us repeat this exercise with Random Forrests\n",
    "\n",
    "\n",
    "In this practical we will repeat the analysis we have done in the previous practical. Instead of DecisionTree classifier we will RandomForest Classifier, an ensemble approach. We will use the same data file.  \n",
    "The data originates form the following publication:\n",
    "\n",
    "https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-016-1292-2\n",
    "\n",
    "```\n",
    "'clinical_biomarkers.csv'\n",
    "``` \n",
    "\n",
    "clinical_biomarkers_raw.csv : file will give you the full ist of raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import IPython.display\n",
    "from sklearn.model_selection import LeaveOneOut, GridSearchCV, KFold, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# own mini- library\n",
    "import session_helpers\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some required data pre-processing\n",
    "\n",
    "Here, you can load a small helper file, allowing to plot the learnt tree using a programme called graphviz.  \n",
    "This library assume that graphviz is installed locally (which is true for the Jupyer Lab environment on bearportal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading the biomarker data and pre-process \n",
    "\n",
    "df = pd.read_csv(\"clinical_biomarkers.csv\")\n",
    "df = df.set_index(['Sample'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Hb (g/dL)  RBC (mil/cmm)   PCV (%)  RET ABS(mil/cmm)   MCV(fL)  \\\n",
      "Sample                                                                   \n",
      "43       0.418995       0.172987  0.571843          1.335644  0.477972   \n",
      "39      -1.215545      -1.542079 -1.763370         -0.079740 -0.148539   \n",
      "27       0.418995      -0.490910 -0.171179         -0.315637  0.425763   \n",
      "11      -0.071367      -0.241948 -0.861128         -1.023329 -0.775051   \n",
      "44      -0.561729       0.034675 -0.277325         -0.787432 -0.409586   \n",
      "73       0.418995       0.919871  0.784135          0.156157 -0.252958   \n",
      "69      -1.378999      -1.016494 -0.754982         -0.315637  0.425763   \n",
      "32      -1.215545      -1.791041 -0.648836          0.392055  1.678786   \n",
      "45       2.053534       1.307144  1.898669         -0.551535  0.530182   \n",
      "57      -2.196269      -2.316625 -2.081808          2.986925  0.582391   \n",
      "65      -1.378999       0.117662 -0.914201         -0.079740 -1.297144   \n",
      "55      -0.398275      -0.739871 -0.118106         -0.079740  0.843438   \n",
      "62       0.582449       1.556105  1.367938         -1.023329 -0.409586   \n",
      "64      -0.725183       0.643247 -0.595763         -1.259227 -1.558190   \n",
      "25       1.072810       1.556105  0.890281         -1.023329 -0.931679   \n",
      "24      -0.071367       0.532598 -0.489617         -0.315637 -1.297144   \n",
      "46      -0.725183      -0.684546 -1.126494         -0.551535 -0.514004   \n",
      "9        0.418995       0.892209 -0.224252          0.392055 -1.401562   \n",
      "78       2.053534       0.449611  2.270180         -0.787432  2.096461   \n",
      "59       0.092087      -0.131299  1.208719          1.099747  1.678786   \n",
      "42      -0.071367       0.449611 -0.436544         -0.787432 -1.140516   \n",
      "7        0.255541       1.085845  0.147259         -0.551535 -1.192725   \n",
      "60      -0.561729       0.338961 -0.648836         -1.259227 -1.244934   \n",
      "2        0.255541       0.283637 -0.277325         -1.259227 -0.722841   \n",
      "52      -0.398275      -0.739871  0.147259          1.807439  1.208903   \n",
      "4       -0.234821       0.477273 -0.595763         -0.079740 -1.349353   \n",
      "31      -1.052091       0.145325 -0.701909          0.863849 -1.088306   \n",
      "56       1.072810       1.113507  2.057888         -0.079740  0.947856   \n",
      "26       0.582449      -0.020649  0.943354          0.392055  1.156693   \n",
      "35      -1.052091      -0.380260 -0.967274         -0.079740 -0.670632   \n",
      "23       0.909356       0.255974  0.147259         -0.315637 -0.148539   \n",
      "48       0.092087      -0.297273  0.200332          0.863849  0.582391   \n",
      "38      -0.234821      -0.933507 -0.436544          0.863849  0.739019   \n",
      "54      -1.542453      -1.846365 -1.498005          1.807439  0.686810   \n",
      "29       1.399718       1.445456  1.421011         -0.315637 -0.252958   \n",
      "41       0.418995      -1.625066  0.306478          0.156157  2.670763   \n",
      "47      -1.215545      -1.514417 -1.073421         -0.315637  0.686810   \n",
      "72       1.726626       1.832729  1.580231         -0.079740 -0.514004   \n",
      "70      -0.071367       1.888054 -0.011960         -1.023329 -2.341330   \n",
      "50      -1.378999      -1.680391 -1.232640         -0.315637  0.739019   \n",
      "68      -1.869361      -1.348443 -1.444932          0.392055  0.008089   \n",
      "53       2.053534       2.220002  2.482472          0.156157  0.060298   \n",
      "12      -0.398275       0.200650 -1.073421         -0.551535 -1.558190   \n",
      "28      -0.234821      -0.020649 -1.020348          1.099747 -1.244934   \n",
      "30       0.255541      -0.075974  0.465697          1.335644  0.634600   \n",
      "1        0.092087      -0.933507  0.677989          1.571541  2.096461   \n",
      "10       0.418995      -0.241948 -0.861128         -1.259227 -0.722841   \n",
      "67       0.255541       0.643247 -0.011960         -0.787432 -0.879469   \n",
      "5        1.072810       1.058183  1.367938         -0.551535  0.269135   \n",
      "33      -0.725183      -1.127144 -0.542690          2.279233  0.895647   \n",
      "\n",
      "        MCH (pg)  MCHC (g/dL)   RDW (%)    PT (s)  APTT (s)  ...  \\\n",
      "Sample                                                       ...   \n",
      "43      0.240766    -0.590677  0.768979  0.078580  1.216529  ...   \n",
      "39      0.720049     1.536617 -0.156403 -1.150734  0.373985  ...   \n",
      "27      1.199332     1.080769 -1.081784  0.031299 -0.545155  ...   \n",
      "11      0.240766     1.688567 -0.248941  1.260614 -0.928130  ...   \n",
      "44     -0.717799    -0.438728 -0.804170  0.220424  0.680365  ...   \n",
      "73     -0.877560    -1.046526  1.694361  0.787800  2.008011  ...   \n",
      "69     -0.078755    -1.046526  0.861517  2.111677  1.829289  ...   \n",
      "32      1.199332    -0.894577 -0.156403 -0.725202 -0.953661  ...   \n",
      "45      0.560288     0.017121 -0.711632  0.456831  0.782491  ...   \n",
      "57      0.560288    -0.134829  2.897357  1.307895  1.190998  ...   \n",
      "65     -1.836125    -0.894577  1.231670 -0.961609  0.246327  ...   \n",
      "55      0.560288    -0.590677  0.213750 -0.441514  1.344188  ...   \n",
      "62     -1.516603    -1.806274 -0.156403 -0.346952  1.701631  ...   \n",
      "64     -1.676364    -0.134829  1.416746 -0.961609 -0.877066  ...   \n",
      "25     -0.877560     0.321020 -1.359399  0.551394  0.322921  ...   \n",
      "24     -0.717799     1.080769 -0.063864 -0.346952 -0.008990  ...   \n",
      "46      0.081006     0.928819  0.028674 -0.346952  1.701631  ...   \n",
      "9      -0.717799     1.232718 -0.248941  0.456831 -0.979193  ...   \n",
      "78      1.678614    -0.742627 -0.248941 -0.867046  0.195263  ...   \n",
      "59      0.240766    -2.262123 -0.248941 -0.819765  0.961213  ...   \n",
      "42     -0.717799     0.776869 -0.804170  0.031299  0.833555  ...   \n",
      "7      -1.197081     0.017121 -0.896708  0.362268 -1.234509  ...   \n",
      "60     -1.037321     0.321020 -0.248941 -0.536077  0.016542  ...   \n",
      "2      -0.078755     1.080769 -1.174322  0.456831  0.195263  ...   \n",
      "52      0.560288    -1.046526 -0.341479  0.409550  0.808023  ...   \n",
      "4      -1.037321     0.776869 -0.526555  1.213332 -0.800471  ...   \n",
      "31     -1.516603    -0.590677 -0.619093 -0.867046 -1.106851  ...   \n",
      "56     -0.238516    -2.110174 -0.989246  1.307895  1.293124  ...   \n",
      "26      0.720049    -0.894577  0.213750 -0.914328  0.016542  ...   \n",
      "35     -0.877560    -0.286778 -0.156403 -1.103453 -0.979193  ...   \n",
      "23      0.720049     1.384668 -0.711632 -0.063264 -0.443028  ...   \n",
      "48      0.400527    -0.286778  0.954056  0.031299 -1.106851  ...   \n",
      "38      1.039571     0.472970 -0.341479  0.267706  0.322921  ...   \n",
      "54      0.879810     0.169071  2.249590 -1.103453 -2.434497  ...   \n",
      "29     -0.398277    -0.286778 -0.896708 -0.110545 -0.034522  ...   \n",
      "41      2.956701     0.169071 -0.711632 -0.630640  0.220795  ...   \n",
      "47      0.560288    -0.286778  0.676441  0.267706  0.859086  ...   \n",
      "72     -0.558038     0.017121  0.583903 -0.725202  0.373985  ...   \n",
      "70     -2.475168     0.017121  0.954056 -1.339860 -0.902598  ...   \n",
      "50      0.720049    -0.134829 -0.063864 -0.536077 -0.085585  ...   \n",
      "68     -0.398277    -0.590677  2.989895 -0.299670  1.063339  ...   \n",
      "53     -0.717799    -1.198476 -0.156403 -0.725202 -1.898332  ...   \n",
      "12     -0.717799     1.536617 -1.081784  0.362268 -1.387699  ...   \n",
      "28     -0.238516     1.840517 -0.248941 -0.867046 -0.723876  ...   \n",
      "30      0.240766    -0.590677  0.028674 -0.394233 -0.519623  ...   \n",
      "1       1.518853    -1.198476 -0.248941  0.740519 -1.132383  ...   \n",
      "10      0.879810     2.752214 -0.341479  1.402458 -0.953661  ...   \n",
      "67     -0.717799     0.472970  0.398826  4.333900  2.084606  ...   \n",
      "5      -0.238516    -0.742627 -1.544475 -0.536077 -1.234509  ...   \n",
      "33      0.720049    -0.286778 -0.063864 -0.299670  0.322921  ...   \n",
      "\n",
      "        M (1000/cmm)  E  (1000/cmm)  B  (1000/cmm)  K (mmol/L)  Ca (mmol/L)  \\\n",
      "Sample                                                                        \n",
      "43         -0.170009      -0.737210       0.254327   -0.489750     0.234956   \n",
      "39         -0.170009       1.879885      -0.807862    0.467285     0.860526   \n",
      "27          1.100586       0.571338      -0.807862    0.467285    -0.807661   \n",
      "11         -0.170009       0.571338      -0.807862    0.467285    -0.077829   \n",
      "44          1.100586       0.571338       1.316516    0.148273    -0.077829   \n",
      "73          1.100586       0.571338      -0.807862    3.019379    -1.328970   \n",
      "69          0.465288      -0.737210      -0.807862   -1.765797    -1.016184   \n",
      "32         -0.805307       0.571338       1.316516    1.105308    -0.182091   \n",
      "45         -0.170009      -0.737210       0.254327    1.743332     1.069050   \n",
      "57          1.735883       0.571338       1.316516   -0.170739    -0.599138   \n",
      "65          1.100586       0.571338      -0.807862    0.467285     0.130694   \n",
      "55          0.465288       0.571338       1.316516    0.148273     0.652003   \n",
      "62         -0.170009      -0.737210      -0.807862   -0.170739     1.486096   \n",
      "64          2.371181       0.571338       1.316516    0.786297    -0.599138   \n",
      "25         -0.805307      -0.737210      -0.807862    0.786297     0.339218   \n",
      "24         -0.170009       0.571338      -0.807862    0.148273    -0.286353   \n",
      "46          0.465288       0.571338       1.316516    2.062343     1.798882   \n",
      "9          -1.440604      -0.737210      -0.807862   -0.170739     0.234956   \n",
      "78          1.100586       0.571338       1.316516    0.148273     0.130694   \n",
      "59         -0.805307      -2.045757       1.316516   -0.170739    -0.599138   \n",
      "42         -0.170009      -0.737210      -0.807862   -0.808762    -0.703399   \n",
      "7          -0.170009      -0.737210      -0.807862    0.148273     0.652003   \n",
      "60         -0.170009      -0.737210      -0.807862    0.148273     0.130694   \n",
      "2          -0.170009      -0.737210      -0.807862    0.786297     0.652003   \n",
      "52         -0.170009       0.571338      -0.807862   -1.446786    -0.494876   \n",
      "4          -1.440604      -0.737210      -0.807862   -0.170739    -0.077829   \n",
      "31         -0.170009      -0.737210      -0.807862    1.105308     0.964788   \n",
      "56         -0.805307      -0.737210       0.254327   -0.808762    -0.703399   \n",
      "26         -0.805307       0.571338       1.316516    0.148273     0.339218   \n",
      "35          1.100586       0.571338      -0.807862    0.467285     0.860526   \n",
      "23         -0.170009       0.571338       1.316516    0.148273     0.652003   \n",
      "48         -0.805307       0.571338       1.316516   -0.808762    -1.016184   \n",
      "38         -0.805307      -0.737210      -0.807862   -1.127774     0.130694   \n",
      "54          1.735883       0.571338      -0.807862    0.467285     2.320190   \n",
      "29         -0.805307      -0.737210      -0.807862   -0.489750    -0.286353   \n",
      "41         -0.170009      -0.737210      -0.807862   -0.170739     2.320190   \n",
      "47         -0.805307      -2.045757       1.316516   -0.489750    -0.911923   \n",
      "72         -0.170009       0.571338       1.316516   -2.403821    -1.433231   \n",
      "70          1.100586       0.571338       1.316516   -1.446786    -1.641755   \n",
      "50          1.100586       0.571338      -0.807862    1.743332     0.234956   \n",
      "68          4.912371       1.879885       2.378705    1.105308    -0.494876   \n",
      "53          0.465288       0.571338       1.316516   -1.127774     1.069050   \n",
      "12         -0.805307       0.571338      -0.807862   -1.127774    -0.182091   \n",
      "28          0.465288       0.571338       1.316516    1.743332     0.756264   \n",
      "30         -0.805307      -0.737210      -0.807862   -1.127774    -0.703399   \n",
      "1          -0.805307      -0.737210       0.254327   -0.170739     0.443479   \n",
      "10         -2.075902      -0.737210      -0.807862   -0.808762    -1.850278   \n",
      "67          1.100586       0.571338      -0.807862   -0.489750    -2.788633   \n",
      "5          -0.805307       0.571338      -0.807862    0.467285     1.694620   \n",
      "33         -1.440604      -0.737210       0.254327    1.424320     1.069050   \n",
      "\n",
      "        IN PHOS(mmol/L)  TOT CHOL (mmol/L)  GLUC (mmol/L)  UREA (mmol/L)  \\\n",
      "Sample                                                                     \n",
      "43             0.983719          -1.864939       0.392634       0.229283   \n",
      "39            -0.403911           0.837319       0.585555      -1.222358   \n",
      "27            -0.866454           0.567094      -0.861349      -0.703914   \n",
      "11            -1.328997           0.296868      -2.018873       0.955104   \n",
      "44             0.521175          -0.784035       0.006793       0.229283   \n",
      "73             0.521175          -1.324487       0.682015       0.125595   \n",
      "69             1.446262          -2.135165       1.067856       1.369858   \n",
      "32             0.983719           0.026642       2.128919      -0.185471   \n",
      "45             0.058632           0.026642       0.489094      -0.703914   \n",
      "57             0.521175           0.296868      -0.186128      -1.948178   \n",
      "65             0.521175          -0.784035       0.585555       0.229283   \n",
      "55            -0.403911           1.377771       0.006793       1.058793   \n",
      "62            -0.403911           1.377771       0.296174      -0.703914   \n",
      "64             1.908805          -0.784035       0.874935       1.577236   \n",
      "25            -0.403911          -1.324487      -0.571969      -1.118669   \n",
      "24            -0.866454          -0.784035      -0.379048      -0.911292   \n",
      "46             0.521175          -0.243584       0.874935      -0.496537   \n",
      "9             -2.254084           0.026642      -2.694095       1.680924   \n",
      "78             0.983719          -0.243584       0.778475       1.991990   \n",
      "59             1.908805          -0.784035       0.874935       0.021906   \n",
      "42            -0.403911          -1.864939       0.489094      -0.289160   \n",
      "7             -2.254084           0.296868      -1.536571       0.955104   \n",
      "60            -1.328997           0.026642      -0.379048      -0.081783   \n",
      "2              0.058632          -0.784035      -1.150730       1.162481   \n",
      "52             0.521175          -1.324487      -0.379048       0.021906   \n",
      "4             -0.403911           0.296868      -1.247191       2.095679   \n",
      "31             0.058632           0.837319       0.199714      -0.496537   \n",
      "56            -0.403911           0.026642       0.006793      -1.533424   \n",
      "26             0.521175          -0.784035       0.296174      -0.703914   \n",
      "35            -0.403911           0.837319       0.296174       1.680924   \n",
      "23            -0.403911          -0.243584      -1.247191      -2.051867   \n",
      "48            -1.328997          -0.243584       0.199714      -1.014980   \n",
      "38             0.521175          -1.594713       0.199714       0.125595   \n",
      "54             0.983719           1.918223       0.103253      -0.807603   \n",
      "29             1.446262           0.567094      -0.475508      -0.289160   \n",
      "41            -0.403911           1.377771       1.067856       0.021906   \n",
      "47             0.521175          -0.513810       1.550157      -0.703914   \n",
      "72             0.058632          -1.594713       0.778475       0.436661   \n",
      "70             0.058632          -0.784035       1.164316       1.991990   \n",
      "50             0.058632           0.026642       0.585555      -1.533424   \n",
      "68             0.521175           0.837319      -0.475508       1.369858   \n",
      "53             1.446262          -0.784035       0.199714      -0.081783   \n",
      "12            -3.641713           1.918223      -1.729492       0.540349   \n",
      "28             0.521175          -0.243584       0.296174       0.644038   \n",
      "30             0.058632           0.026642      -0.861349       0.021906   \n",
      "1              0.983719           1.107545      -2.501174      -0.185471   \n",
      "10            -0.866454           0.296868      -0.668429       0.644038   \n",
      "67             0.521175          -1.594713       1.550157       0.125595   \n",
      "5             -0.866454           1.647997      -0.186128       0.021906   \n",
      "33             0.521175           1.107545       0.392634      -1.014980   \n",
      "\n",
      "        TRIGS (umol/L)  \n",
      "Sample                  \n",
      "43           -0.804555  \n",
      "39            1.851883  \n",
      "27           -1.104153  \n",
      "11           -0.504957  \n",
      "44           -0.385117  \n",
      "73           -0.804555  \n",
      "69           -1.124126  \n",
      "32            1.292633  \n",
      "45           -0.484983  \n",
      "57           -0.724662  \n",
      "65            0.174133  \n",
      "55            0.773329  \n",
      "62           -0.065546  \n",
      "64            0.234052  \n",
      "25           -0.205358  \n",
      "24           -0.484983  \n",
      "46            2.151481  \n",
      "9            -0.664742  \n",
      "78           -0.305225  \n",
      "59           -0.584850  \n",
      "42           -0.864475  \n",
      "7             0.513677  \n",
      "60            1.272660  \n",
      "2            -1.363805  \n",
      "52           -0.185385  \n",
      "4            -1.044234  \n",
      "31            0.433785  \n",
      "56            0.154159  \n",
      "26            1.791963  \n",
      "35            2.111535  \n",
      "23           -1.064207  \n",
      "48           -0.205358  \n",
      "38           -1.343832  \n",
      "54            3.030303  \n",
      "29           -1.084180  \n",
      "41            1.172794  \n",
      "47           -0.764608  \n",
      "72            0.014347  \n",
      "70            0.094240  \n",
      "50            1.592231  \n",
      "68            0.373865  \n",
      "53           -0.684716  \n",
      "12           -0.744635  \n",
      "28            0.533651  \n",
      "30           -1.024260  \n",
      "1            -1.184046  \n",
      "10           -0.884448  \n",
      "67           -0.604823  \n",
      "5            -0.724662  \n",
      "33            0.993035  \n",
      "\n",
      "[50 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "df_ex = df.copy()\n",
    "df_ex['Response'] = df_ex['Response'].map(\n",
    "    {\n",
    "        'C.':'C.',\n",
    "        'C. R.':'C. R.',\n",
    "        'Low':'Low',\n",
    "        'Int. I.':'Int. I.',\n",
    "        'Int. II.':'Int. II.',\n",
    "        'Int. II. R.':'Int. II. R.',\n",
    "        'High':'High',\n",
    "        'High R.':'High R.',\n",
    "    })\n",
    "\n",
    "df_ex = df_ex[df_ex['Response'].notna()]\n",
    "\n",
    "# For consitency\n",
    "# target column\n",
    "y = df_ex['Response']\n",
    "# this drops the column 'Response' for the dataframe and stores it in X\n",
    "X = df_ex.drop(['Response'],axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=3)\n",
    "\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the RandomForest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'n_estimators': [2,3,5], \n",
    "    'max_depth':[1,2,3,4],\n",
    "    'min_samples_leaf':[2,5,10]\n",
    "}\n",
    "\n",
    "random_f_model = RandomForestClassifier() \n",
    "rf_grid_search = GridSearchCV(random_f_model, parameters, cv=5,scoring='balanced_accuracy') # weighted == F1 Measure for multi-class\n",
    "grid_search = rf_grid_search.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_random_f_model = rf_grid_search.best_estimator_ # best model according to grid search \n",
    "\n",
    "best_random_f_model.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-use the model on another dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # plotting and visulisation\n",
    "import seaborn as sns # nicer (easier) visualisation\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import RocCurveDisplay,accuracy_score,roc_curve\n",
    "\n",
    "## Evaluate on test data\n",
    "y_test_predicted = best_random_f_model.predict(X_test)\n",
    "\n",
    "\n",
    "print('Confusion Matrix of best model on test')\n",
    "print(confusion_matrix(y_test,y_test_predicted))\n",
    "print(\"Decision Tree Accuracy on test data: \", accuracy_score(y_test, y_test_predicted))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your Task : Train a Decision Tree Classifier and apply it on the test data set. \n",
    "\n",
    "- Task 1 : Train a decision tree classifier on the open ml Lipid data set. \n",
    "Data Link : https://openml.org/search?type=data&status=active&id=1480\n",
    "\n",
    "- Task 2 : Split the data in to train and test [30% for the test] \n",
    "\n",
    "- Task 3 : Using a five fold cross validation and within the cross validation lopp\n",
    "    Task 3.1 Train a Decision Tree Classifier\n",
    "    Task 3.2 Train a Random Forest Classifier\n",
    "    \n",
    "- Task 4 : Train a Decision Tree and Random Forest using all Train data. Apply both trained classifier on the test data. \n",
    "\n",
    "#### Question  1: Which classifier perform best based on F1 score ?\n",
    "#### Question  2: Which classifier perform best based on Accuracy ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.model_selection import LeaveOneOut, GridSearchCV, KFold, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "\n",
    "## Task 1 : Load the open ML lipid data set. \n",
    "# lipid_data = ...\n",
    "\n",
    "# ... complete rest of the section ... ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=3)\n",
    "\n",
    "## dt_model = ...\n",
    "## rf_model = ...\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, random_state=15, shuffle=True)\n",
    "for count_k,(train_index, test_index) in enumerate(kf.split(X,y)):\n",
    "    X_train = X.iloc[train_index]\n",
    "    X_test  = X.iloc[test_index]\n",
    "    y_train = y.iloc[train_index]\n",
    "    y_test  = y.iloc[test_index]\n",
    "    ## .... Complete this section ... ##   "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "27504229a786ecc4bac7f6801848e44cb1a63648e4d666cbb9fdea5e9f215e02"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
